"use strict";(self.webpackChunkApache_2_0=self.webpackChunkApache_2_0||[]).push([[3312],{6207:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"/2020/08/10/introducing-QA-Board","metadata":{"permalink":"/qaboard/blog/2020/08/10/introducing-QA-Board","editUrl":"https://github.com/Samsung/qaboard/edit/master/website/blog/blog/2020-08-10-introducing-QA-Board.md","source":"@site/blog/2020-08-10-introducing-QA-Board.md","title":"Introducing QA-Board","description":"We are happy to introduce QA-Board (source), a run-tracker with advanced visualizations for algorithm and software engineers.","date":"2020-08-10T00:00:00.000Z","formattedDate":"August 10, 2020","tags":[{"label":"qualityOps","permalink":"/qaboard/blog/tags/quality-ops"},{"label":"engineering","permalink":"/qaboard/blog/tags/engineering"}],"readingTime":3.025,"truncated":true,"authors":[{"name":"Arthur Flam","title":"Algo engineering at Samsung","url":"https://shapescience.xyz/","imageURL":"https://avatars.githubusercontent.com/u/2649055","key":"arthurf"}],"frontMatter":{"title":"Introducing QA-Board","authors":["arthurf"],"tags":["qualityOps","engineering"]},"nextItem":{"title":"Creating and viewing flame graphs with QA-Board","permalink":"/qaboard/blog/2020/06/24/flame-graphs"}},"content":"We are happy to introduce [QA-Board](https://samsung.github.io/qaboard) ([source](https://github.com/samsung/qaboard)), a run-tracker with advanced visualizations for algorithm and software engineers.\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\n<p align=\\"center\\">\\r\\n  <img alt=\\"QA-Board logo\\" width={400} src=\\"https://user-images.githubusercontent.com/2649055/86829138-bb6aef00-c09c-11ea-8b59-78b7fc44ebcf.png\\"/>\\r\\n</p>\\r\\n\\r\\n\\r\\n## Tracking quality is hard\\r\\n_Tests are not enough_ when the focus is quality and performance. Whether you need to improve algorithms or make performance-sensitive code more efficient, all sorts of metrics and visualizations are required. Engineers usually start this evaluation process by writing scripts or notebooks that test their solution on limited samples. They then look at the results and iterate.\\r\\n\\r\\nWhile it\'s very convenient at first, very soon keeping track of versions or comparing features gets challenging. There are a lot of \\"logistics\\" to get right:\\r\\n- How to share results?\\r\\n- What about source control and CI integration?\\r\\n- How to start distributed tuning experiments?\\r\\n- How to identify regressions?\\r\\n\\r\\n> We wanted to solve those recurrent issues with a simple solution adaptable to many projects.\\r\\n\\r\\n\\r\\n## QA-Board\'s story\\r\\nOur business unit develops IP for image sensors. What was a closely-knit 15 person team became an over-300-person organization. The complexity and pace of our projects kept growing. As you may know, Samsung is now working on image sensors with groundbreaking resolution (200MP and beyond), capable of AI and packed with innovative features, including cutting-edge image processing IPs.\\r\\n\\r\\n> [We\'re hiring at Samsung\'s Israel R&D Center](https://samsung-careers.co.il/?coref=1.10.rA7_407&t=1597396535199) - our goal is to become the 1st image sensor manufacturer worldwide.\\r\\n\\r\\nAs we were experiencing growing pains in our development processes, we set up an infrastructure team to change the way we work. What we emphasized were software-engineering best practices, tooling, reproducibility, and our mission to improve cross-team collaboration.\\r\\n\\r\\nAs part of our work on algorithms for our [innovative DVS sensor](http://rpg.ifi.uzh.ch/docs/CVPR19workshop/CVPRW19_Eric_Ryu_Samsung.pdf), I had created what became QA-Board. When I joined this new infrastructure team we expanded QA-Board\'s scope.\\r\\n\\r\\n## Use-Cases\\r\\nQA-Board has become a key collaborative tool. Our main use-cases are:\\r\\n- **Sharing** links with all the info (command, output files, logs...).\\r\\n- **Work-from-home**: engineers can share 108MP+ images thanks to the [IIIF protocol](https://github.com/IIIF/awesome-iiif).\\r\\n- **Integration**: links to and from git repositories and their Continuous Integration. From QA-Board, users can [directly access](https://samsung.github.io/qaboard/docs/triggering-third-party-tools) build artifacts, trigger automated jobs, and when needed they can build dashboards or scripts they query QA-Board\'s API.\\r\\n- **Visualizations**: everything can be compared, and thanks to the [many different types of visualizations](https://samsung.github.io/qaboard/docs/visualizations) (images/plots/text/html/video...), users can easily create the reports they need.\\r\\n- **Tuning**: QA-Board [distributes runs](https://samsung.github.io/qaboard/docs/celery-integration) to our cluster. Users can easily start tuning experiments that enable feature flags or tweak parameters. We\'ve integrated [scikit-optimize](https://scikit-optimize.github.io/) for black-box optimization.\\r\\n- **Regression**: users can check the progress on various metrics, and when needed, identify which commit caused a regression.\\r\\n- **Performance engineering**: save [`rr`](https://rr-project.org/)/[`perf`](http://www.brendangregg.com/perf.html) recordings, view [flame graphs](http://www.brendangregg.com/flamegraphs.html), [benchmark drivers](https://github.com/arthur-flam/sysbench-qaboard), and track metrics for regressions.\\r\\n\\r\\n> Here are some screenshots (from slide 7):\\r\\n\\r\\n<figure class=\\"video-container\\">\\r\\n  <iframe src=\\"//www.slideshare.net/slideshow/embed_code/key/C3QrOdYHrRyB7d\\" width=\\"595\\" height=\\"485\\" frameborder=\\"0\\" marginwidth=\\"0\\" marginheight=\\"0\\" scrolling=\\"no\\" style={{border: \\"1px solid #CCC\\", borderWidth: \\"1px\\", marginBottom: \\"5px\\", maxWidth: \\"100%\\"}} allowfullscreen></iframe>\\r\\n</figure>\\r\\n\\r\\n\\r\\n## What\'s next?\\r\\nOur goal is to make QA-Board the best general-purpose run-tracker. We want to see it used for performance optimization, algorithm development, model comparaisons in operational research, web page performance tracking...\\r\\n\\r\\nTo achieve those goals, we\'ll need:\\r\\n- **User feedback**, issues and feature requests. \\r\\n- **Community contributions**, for instance integrating more file viewers: e.g. support for common plot formats like vega or highcharts...\\r\\n\\r\\n:::note How to get in touch?\\r\\nJoin our [issue tracker](https://github.com/Samsung/qaboard/issues) to report bugs or suggest features, or feel free to [start a chat](https://spectrum.chat/qaboard) with [the maintainers](mailto:arthur.flam@samsung.com).\\r\\n:::\\r\\n\\r\\n## How to get started using QA-Board?\\r\\n[Head over to the docs](https://samsung.github.io/qaboard/docs/deploy). If you run into issues contact us: we\'ll help you."},{"id":"/2020/06/24/flame-graphs","metadata":{"permalink":"/qaboard/blog/2020/06/24/flame-graphs","editUrl":"https://github.com/Samsung/qaboard/edit/master/website/blog/blog/2020-06-24-flame-graphs.md","source":"@site/blog/2020-06-24-flame-graphs.md","title":"Creating and viewing flame graphs with QA-Board","description":"Many tools exist to investigate software performance. QA-Board can now use flame graphs to help identify bottlenecks, and pointpoint why regressions happened thanks to differential frame graphs.","date":"2020-06-24T00:00:00.000Z","formattedDate":"June 24, 2020","tags":[{"label":"performance","permalink":"/qaboard/blog/tags/performance"},{"label":"engineering","permalink":"/qaboard/blog/tags/engineering"},{"label":"visualization","permalink":"/qaboard/blog/tags/visualization"}],"readingTime":3.165,"truncated":true,"authors":[{"name":"Arthur Flam","title":"Algo engineering at Samsung","url":"https://shapescience.xyz/","imageURL":"https://avatars.githubusercontent.com/u/2649055","key":"arthurf"}],"frontMatter":{"title":"Creating and viewing flame graphs with QA-Board","tags":["performance","engineering","visualization"],"image":"https://samsung.github.io/qaboard/img/slides/flame-graphs.jpg","authors":["arthurf"],"hide_table_of_contents":false},"prevItem":{"title":"Introducing QA-Board","permalink":"/qaboard/blog/2020/08/10/introducing-QA-Board"}},"content":"import useBaseUrl from \'@docusaurus/useBaseUrl\';\\n\\n[Many tools](https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55) exist to investigate software performance. QA-Board can now use flame graphs to help identify bottlenecks, and pointpoint why regressions happened thanks to differential frame graphs.\\n\\n\x3c!--truncate--\x3e\\n\\n> If you are not familiar with flame graphs [read this](http://www.brendangregg.com/flamegraphs.html)!\\n\\n## System requirements\\n1. Install `perf`.\\n\\n```bash\\n# debian\\nsudo apt-get install -y linux-tools-generic linux-tools-$(uname -r)\\n# maybe also            linux-tools-common\\n\\n# from source\\ngit clone https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git\\ncd linux/tools/perf\\nmake\\n\\n# install somewhere in your PATH\\ncp perf /somewhere/bin\\n```\\n\\n2. Install `FlameGraph`. It turns `perf` recording into flame graphs:\\n```bash\\ngit clone https://github.com/brendangregg/FlameGraph\\ncd FlameGraph\\n\\n# make the scripts accessible easily\\nexport PATH=$(pwd):$PATH\\n```\\n\\n3. `burn` transforms the output from `FlameGraph` into a \\"portable\\" json.\\n\\n```bash\\n# other options at https://github.com/spiermar/burn#getting-started\\ncurl -L \\"https://dl.bintray.com/mspier/binaries/burn/1.0.1/linux/amd64/burn\\" -o burn\\nchmod +x burn\\n\\n# install somewhere in your PATH\\ncp burn /somewhere/bin\\n```\\n\\n\\n## Requirements for C/C++\\n1. Your program needs to be compiled with symbols (`gcc -g`, otherwise, have fun making sense of the adresses). If your\'re not sure call `file your-binary`,  it will tell you:\\n\\n\\n```bash\\n$ file my-binary\\nmy-binary: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/l, for GNU/Linux 2.6.32, with debug_info, not stripped\\n```\\n\\n2. Ideally, compile with `gcc -fno-omit-frame-pointer` as frame pointers help create good stack traces. If you can\'t do it, `perf --call-graph dwarf` or `perf --call-graph lbr` [may be workarounds](http://www.brendangregg.com/perf.html)...\\n\\n> It\'s also possible to build flame graphs for java, node...\\n\\n\\n## Using `perf` to instrument a command\\nRead this [article by Brendan Gregg](http://www.brendangregg.com/perf.html) to get an overview of `perf`\'s many uses and commands.\\nTo profile a command:\\n\\n```bash\\nperf record -F 99 -ag -- your-command\\n# -a: all CPUs\\n# -g: capture call graphs (stack traces)\\n# -F99: sample at 99 Hertz\\n\\n# view a report with\\nperf report\\n```\\n\\n:::note\\n`perf` may warn about you not having permissions to collect stats from the kernel. If it happens, either run as root with `sudo` or follow the instructions, likely involving `CAP_SYS_ADMIN` permissions for your users, and a `<=2` policy in _/proc/sys/kernel/perf_event_paranoid_...\\n:::\\n\\n[Read the docs](https://www.man7.org/linux/man-pages/man1/perf-record.1.html) to tweak profiles to your use case.\\n\\n> As-is, `perf`\'s reports are great. The issue is that if you\'re investigating multiple feature flags, compilation options or code versions, you need a way to organize all this data. And obviously still have good investigation and debugging tools. That\'s the promise of [QA-Board](https://samsung.github.io/qaboard)!\\n\\n## Flame graphs at last!\\nCreate a flame graph involves lots of format conversion. You can create an SVG flame graph:\\n\\n```bash\\n# use a text-based format for the perf recordings\\nperf script > out.perf\\n\\n# this format makes filtering super-easy\\nstackcollapse-perf.pl out.perf > out.perf-folded\\n\\n# create an SVG plot, already viewable\\nflamegraph.pl out.perf-folded > perf.svg\\n```\\n\\nIf you only care about some functions (e.g. what\'s under your `main()`), you can filter:\\n\\n```bash\\ncat out.perf-folded \\\\\\n  # our software has a bunch of irrelevant setup code\\n  | grep \'CCDECmdLineSim::RunChain\' \\\\\\n  # remove common frame prefixes\\n  | sed \'s/;\\\\[unknown\\\\];__libc_start_main;main;CCDECmdLineSim::Run//g\' \\\\\\n  | tee out.filtered.perf-folded \\\\\\n  # tons of options.. https://github.com/brendangregg/FlameGraph#options\\n  | flamegraph.pl --color hot --hash --cp \\\\\\n  > perf.svg\\n\\n# cleanup\\nrm out.perf out.perf-folded\\n```\\n\\nQA-Board\'s viewer needs a more \\"portable\\" format, not an \\"finished\\" SVG:\\n\\n```bash\\nburn convert --type=folded out.filtered.perf-folded --output=perf.flame.json\\n```\\n\\n\\n## Visualizing flame graphs in QA-Board\\nQA-Board integrates Martin Spier\'s [`d3-flame-graph`](https://github.com/spiermar/d3-flame-graph). At a glance, you can check where you code spends its CPU cycles, and use [differential flame graphs]((http://www.brendangregg.com/blog/2014-11-09/differential-flame-graphs.html)) to debug regressions. What do you need to do?\\n\\n1. Wrap calls to `perf` & cie in your `run()` function:\\n\\n```python title=\\"qa/main.py\\"\\ndef run(context):\\n    # run perf -- /some/binary\\n    # run stackcollapse.pl && burl -o {context.output_dir}/perf.flame.json\\n```\\n\\n2. Tell you expect to view flame graphs:\\nQA-Board\\n```yaml title=\\"qaboard.yaml\\"\\noutputs:\\n  visualizations:\\n  - path: perf.flame.json\\n```\\n\\n<img alt=\\"Flame graph viewer\\" src={useBaseUrl(\'img/slides/flame-graphs.jpg\')} />\\n\\n<img alt=\\"Flame graph viewer\\" src=\\"/img/slides/flame-graphs.jpg\\" />"}]}')}}]);